from pathlib import Path
from typing import List

import json
import time
import openai
import os
import csv

class DebugBuildClassifier:

    dbg_info: str
    
    delimiter = "###"

    def __init__(self, filename: str):
        dbg_output = Path.cwd() / filename
        with dbg_output.open(mode='r', encoding='utf-8') as dbg_file:
            self.dbg_info = str(dbg_file.read())

    @property
    def system_message(self):
        return f'''You are an expert at cmake. You are able to diagnose build errors and predict  
why they occur as well as suggest a fix. You will be provided with the logs 
generated by running the trigger command delimited with `{self.delimiter}` characters.

Logs will be provided to you in the next message.
For now, learn the following in order to help me.

The trigger command is "cmake -DCMAKE_BUILD_TYPE=Debug .. && cmake --build ."
Follow the steps on the logs to find out the <<<diagnosis>>>

Step 1 = Split the output into it's each section on the delimtier '--'
Step 2 = You first classify each line by 1. Positive 2. Negative

positive - indicate success in build (can include skipped)
Negative - messages that suggest (failed or not-done)

Step 3
------

Let <diagnosis> be initialzed to an empty array i.e, []

For each negatively classififed line, add to the <<diagnosis>> array, the following json - 
    {{
        'line' : <string representing the negative line in the log>
        'cause' : <string describing the meaning and cause of error>
        'commands': <list of commands to run to resolve it otherwise 'N/A'>
        'criticality' : <int score (0 to 1) 1 being the most critical and 0 the least>
    }}

Output <<<diasnosis>>>'''


    def _get_completion_from_messages(self, messages, 
        model="gpt-3.5-turbo", 
        temperature=0,
        max_tokens=500):

        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            temperature=temperature, 
            max_tokens=max_tokens,
        )
        return response.choices[0].message["content"]


    def test_run(self):
        messages = [
            { 'role': 'system', 'content' : 'You are a mathematician' },
            { 'role' : 'user', 'content' : 'What is the approxiamate value of PI ? '}
        ]
        response = self._get_completion_from_messages(messages)
        print(response)


    def run(self, partial = -1):

        build_lines = self.dbg_info.split("\n")
        total_lines = len(build_lines)
        line_buffer_size = 20 # number of lines to be processed at a time

        number_of_buffers = int((total_lines + line_buffer_size - 1) / line_buffer_size) if partial == -1 else  partial

        with open('results.csv', 'w') as f:

            writer = csv.DictWriter(
                f,
                fieldnames=["line", "cause", "commands", "criticality"], 
                delimiter=',', quotechar='"'
            )

            writer.writeheader()
        

            for i in range(0, number_of_buffers):

                start_pos = i * line_buffer_size
                end_pos = min(start_pos + line_buffer_size, total_lines)

                data: List[str] = build_lines[start_pos: end_pos]
                debug_data_buffer = '\n'.join(data)
                
                messages =  [  
                    {  
                        'role': 'system',
                        'content': self.system_message
                    },    
                    {   
                        'role':'user', 
                        'content': f'''{self.delimiter}
                            -- Looking for shm_open in rt - not found
                            -- wget: command not found
                        {self.delimiter}'''
                    },
                    {
                        'role': 'assistant',
                        'content': json.dumps([
                            { 
                                'line': 'Looking for shm_open in rt - not found',
                                'cause': 'the build system is looking for a function called "shm_open" in the "rt" library but it was not found.',
                                'commands': [ 'sudo apt-get update', 'sudo apt-get install linux-rt' ],
                                'criticality': 0.5
                            },
                            { 
                                'line': 'wget: command not found',
                                'cause': 'wget is a command line utility has not been installed.',
                                'commands': [ 'sudo apt-get update', 'sudo apt install wget' ],
                                'criticality': 0.5
                            }
                        ]),
                    }, 
                    {   
                        'role':'user', 
                        'content': f'''{self.delimiter}{debug_data_buffer}{self.delimiter}'''
                    },
                ] 
                
                print(f'Processing line {start_pos} to {end_pos} ')
                response = self._get_completion_from_messages(messages)

                try:
                    parsed_response = json.loads(response.replace("'", '"'))

                    for suggestion in parsed_response:
                        writer.writerow(suggestion)
                        
                except Exception as e:
                    print(e)
                    print("Unable to parse response", response)
                    pass

                f.flush()
                time.sleep(15) # satisfy api request limit on openai server